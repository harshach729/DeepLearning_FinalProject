{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e284fd8f92af46a58ae8236b2adbd69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6af4d119a92e49c08e06ef73e011166d",
              "IPY_MODEL_1f8e4998eb8d43bab378afb9e60a11c1",
              "IPY_MODEL_2aab8bec1dff48eb9dd1e0d8039664bc"
            ],
            "layout": "IPY_MODEL_c376b766a39f4c0c8bb4cf1e6bb82ec0"
          }
        },
        "6af4d119a92e49c08e06ef73e011166d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2638d11a7dcd4626afaf81ee7d93b312",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c8b46fbb42417d9fc808aaa58515ac",
            "value": "100%"
          }
        },
        "1f8e4998eb8d43bab378afb9e60a11c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adb071d093f94c2fa42a1619d16f37e7",
            "max": 76,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_524a40c1f4134ea8b27352a88c4e706f",
            "value": 76
          }
        },
        "2aab8bec1dff48eb9dd1e0d8039664bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f499e997eab94603bc85e233c3b9d326",
            "placeholder": "​",
            "style": "IPY_MODEL_d169a0270e1343e1821f4b93e961100f",
            "value": " 76/76 [00:06&lt;00:00, 11.95it/s]"
          }
        },
        "c376b766a39f4c0c8bb4cf1e6bb82ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2638d11a7dcd4626afaf81ee7d93b312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c8b46fbb42417d9fc808aaa58515ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adb071d093f94c2fa42a1619d16f37e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524a40c1f4134ea8b27352a88c4e706f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f499e997eab94603bc85e233c3b9d326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d169a0270e1343e1821f4b93e961100f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc38737926da414e8499272bec72ec89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73fcc29969874f27bfe116f335326dd9",
              "IPY_MODEL_365bdc1cfdfd4c94b6aaea0be1abc528",
              "IPY_MODEL_b00379fd307b4c959200bcad16679d33"
            ],
            "layout": "IPY_MODEL_5699694818254d199f9c4cc5dd938883"
          }
        },
        "73fcc29969874f27bfe116f335326dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a86f90ceec4e72a4ee4e413705f93d",
            "placeholder": "​",
            "style": "IPY_MODEL_fce30c68b50c451db8b1534692ed4225",
            "value": "100%"
          }
        },
        "365bdc1cfdfd4c94b6aaea0be1abc528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2164ad6388194dc68c1fc8a98ea53ebb",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43ec48e4a2504abbb56b0b2e18b780b0",
            "value": 11
          }
        },
        "b00379fd307b4c959200bcad16679d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17cb051dafef476f9a400e31da31d8d6",
            "placeholder": "​",
            "style": "IPY_MODEL_45b6dd57a2194b3bb7bac23bb889069c",
            "value": " 11/11 [00:00&lt;00:00, 26.28it/s]"
          }
        },
        "5699694818254d199f9c4cc5dd938883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a86f90ceec4e72a4ee4e413705f93d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce30c68b50c451db8b1534692ed4225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2164ad6388194dc68c1fc8a98ea53ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ec48e4a2504abbb56b0b2e18b780b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17cb051dafef476f9a400e31da31d8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b6dd57a2194b3bb7bac23bb889069c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd82d041a1314655a29509b0fe35ee73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88eedcc1db5440848fbbfe7eaf7fb32c",
              "IPY_MODEL_f214fb40840d4e4197da005e58c8cf35",
              "IPY_MODEL_fc11f0671beb4bc0b8ddcf4f3c3eb3d0"
            ],
            "layout": "IPY_MODEL_5c217c78db6b4d998bdc5d1bbf4b6d38"
          }
        },
        "88eedcc1db5440848fbbfe7eaf7fb32c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d53703d84da49d98551241451fe344d",
            "placeholder": "​",
            "style": "IPY_MODEL_99e046e350cb487ca33577b21e1bcb26",
            "value": ""
          }
        },
        "f214fb40840d4e4197da005e58c8cf35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6494f54475cd40a0bb857e58e8c810fb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46f997effcfc47c7bcdacbb2eb6a20bb",
            "value": 0
          }
        },
        "fc11f0671beb4bc0b8ddcf4f3c3eb3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de1b31bfcacb40a7baecb2120358463d",
            "placeholder": "​",
            "style": "IPY_MODEL_89b8fc79b6054408809a9241cfe60276",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "5c217c78db6b4d998bdc5d1bbf4b6d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d53703d84da49d98551241451fe344d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99e046e350cb487ca33577b21e1bcb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6494f54475cd40a0bb857e58e8c810fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "46f997effcfc47c7bcdacbb2eb6a20bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de1b31bfcacb40a7baecb2120358463d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b8fc79b6054408809a9241cfe60276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63463bfac7fd40ddbeaf06ad1e17ea72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05b78a4d3614be3bc9c77d90bea841d",
              "IPY_MODEL_8da09e5096854ca08fcf081b386a363a",
              "IPY_MODEL_280008a6ebc64b2fb3bba9229aad5c7d"
            ],
            "layout": "IPY_MODEL_71b812a239c64793b049d80d7abd9ab8"
          }
        },
        "e05b78a4d3614be3bc9c77d90bea841d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1d38d947e7417b9ecf3237800600c7",
            "placeholder": "​",
            "style": "IPY_MODEL_97bd57b6166d4eaebe17e5ebc55f34fe",
            "value": "100%"
          }
        },
        "8da09e5096854ca08fcf081b386a363a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7b824012d2547fd84066fa2de962e6a",
            "max": 178793939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_908e4d82965c4b588bbc0cb75b735366",
            "value": 178793939
          }
        },
        "280008a6ebc64b2fb3bba9229aad5c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f52ef05259a4d658922776a239ab0bb",
            "placeholder": "​",
            "style": "IPY_MODEL_a87744d0a4854cb3aa0b05257e5be59f",
            "value": " 171M/171M [00:02&lt;00:00, 65.9MB/s]"
          }
        },
        "71b812a239c64793b049d80d7abd9ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1d38d947e7417b9ecf3237800600c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97bd57b6166d4eaebe17e5ebc55f34fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7b824012d2547fd84066fa2de962e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "908e4d82965c4b588bbc0cb75b735366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f52ef05259a4d658922776a239ab0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a87744d0a4854cb3aa0b05257e5be59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cbb95d29ecd4a63b3d9735032a02c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b45e965d69b47bb8bca9daefbe0cb7b",
              "IPY_MODEL_d7f0c021923f42bc836fb8ed46bccc4a",
              "IPY_MODEL_8df1b0e48dd94080964c1a3c071826f3"
            ],
            "layout": "IPY_MODEL_c9c690a2212141469eaad0a41b7c3a69"
          }
        },
        "5b45e965d69b47bb8bca9daefbe0cb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ded0612e7149c391af8442b3814a28",
            "placeholder": "​",
            "style": "IPY_MODEL_a882b9c989cc4075b3b85f3dfd791b5d",
            "value": "100%"
          }
        },
        "d7f0c021923f42bc836fb8ed46bccc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2c8c26f9f094e5b910ddd28336afc98",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2f39660aadc468abd5285e68e5b236e",
            "value": 3
          }
        },
        "8df1b0e48dd94080964c1a3c071826f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44dd53f5ac6f47f18e19c8e4ce6204f9",
            "placeholder": "​",
            "style": "IPY_MODEL_e4a4e196afa0483fb9a0585b4fc7e3f3",
            "value": " 3/3 [02:29&lt;00:00, 49.50s/it]"
          }
        },
        "c9c690a2212141469eaad0a41b7c3a69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ded0612e7149c391af8442b3814a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a882b9c989cc4075b3b85f3dfd791b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2c8c26f9f094e5b910ddd28336afc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f39660aadc468abd5285e68e5b236e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44dd53f5ac6f47f18e19c8e4ce6204f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a4e196afa0483fb9a0585b4fc7e3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install required libraries"
      ],
      "metadata": {
        "id": "zQdviM-hxTDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.1.0\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_t5J2LBxSx2",
        "outputId": "d5a5000f-2862-4739-98a6-8f29f3ee890d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0.tar.gz (15.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.6 MB 75.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: scipy\n",
            "  Building wheel for scipy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scipy: filename=scipy-1.1.0-cp38-cp38-linux_x86_64.whl size=41832680 sha256=cc8930a9494643bdd5089f9cc8ed49a897bbd4183401ce55484af320c944b948\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/a9/5e/9e4eddde37a1e15cf5cb404ba197df482cc39ffbfef91ec337\n",
            "Successfully built scipy\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.3.0 requires scipy>=1.5, but you have scipy 1.1.0 which is incompatible.\n",
            "pymc 4.1.4 requires scipy>=1.4.1, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.1.0 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.1.0 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.1.0 which is incompatible.\n",
            "aeppl 0.0.33 requires scipy>=1.4.0, but you have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset"
      ],
      "metadata": {
        "id": "gO2o9BUHx5Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1vnychf9-SDY4RSOFF1KJxCxS-_0L9y61\n",
        "!gdown 1tsqnXIWi_gAlN87FLzxldygoYaa3BCrv\n",
        "!gdown 1XhdV9YQyzlqBVqVkd5Jon1jqkzzRNo1T"
      ],
      "metadata": {
        "id": "1DNZ2_BtxToI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b3fc65-c8bf-4de0-ebef-6b5b5ad3b8cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vnychf9-SDY4RSOFF1KJxCxS-_0L9y61\n",
            "To: /content/data.zip\n",
            "100% 82.1M/82.1M [00:00<00:00, 132MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tsqnXIWi_gAlN87FLzxldygoYaa3BCrv\n",
            "To: /content/data.json\n",
            "100% 19.1k/19.1k [00:00<00:00, 15.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XhdV9YQyzlqBVqVkd5Jon1jqkzzRNo1T\n",
            "To: /content/caption.txt\n",
            "100% 2.42k/2.42k [00:00<00:00, 2.32MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw92LynK-exn",
        "outputId": "d3498197-0b26-4a73-e1e5-248da02211c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: data/1.jpeg             \n",
            "  inflating: data/10.jpeg            \n",
            "  inflating: data/100.jpg            \n",
            "  inflating: data/11.jpeg            \n",
            "  inflating: data/12.jpeg            \n",
            "  inflating: data/13.jpeg            \n",
            "  inflating: data/14.jpeg            \n",
            "  inflating: data/15.jpg             \n",
            "  inflating: data/16.jpeg            \n",
            "  inflating: data/17.jpg             \n",
            "  inflating: data/18.jpg             \n",
            "  inflating: data/19.jpg             \n",
            "  inflating: data/2.jpeg             \n",
            "  inflating: data/20.jpg             \n",
            "  inflating: data/21.jpg             \n",
            "  inflating: data/22.jpg             \n",
            "  inflating: data/23.jpg             \n",
            "  inflating: data/24.jpg             \n",
            "  inflating: data/25.jpg             \n",
            "  inflating: data/26.jpg             \n",
            "  inflating: data/27.jpg             \n",
            "  inflating: data/28.jpg             \n",
            "  inflating: data/29.jpg             \n",
            "  inflating: data/3.jpeg             \n",
            "  inflating: data/30.jpg             \n",
            "  inflating: data/31.jpg             \n",
            "  inflating: data/32.jpg             \n",
            "  inflating: data/33.jpg             \n",
            "  inflating: data/34.jpg             \n",
            "  inflating: data/35.jpg             \n",
            "  inflating: data/36.jpg             \n",
            "  inflating: data/37.jpg             \n",
            "  inflating: data/38.jpg             \n",
            "  inflating: data/39.jpg             \n",
            "  inflating: data/4.jpeg             \n",
            "  inflating: data/40.jpg             \n",
            "  inflating: data/41.jpg             \n",
            "  inflating: data/42.jpg             \n",
            "  inflating: data/43.jpg             \n",
            "  inflating: data/44.jpg             \n",
            "  inflating: data/45.jpg             \n",
            "  inflating: data/46.jpg             \n",
            "  inflating: data/47.jpg             \n",
            "  inflating: data/48.jpg             \n",
            "  inflating: data/49.jpg             \n",
            "  inflating: data/5.jpeg             \n",
            "  inflating: data/50.jpg             \n",
            "  inflating: data/51.jpg             \n",
            "  inflating: data/52.jpg             \n",
            "  inflating: data/53.jpg             \n",
            "  inflating: data/54.jpg             \n",
            "  inflating: data/55.jpg             \n",
            "  inflating: data/56.jpg             \n",
            "  inflating: data/57.jpg             \n",
            "  inflating: data/58.jpg             \n",
            "  inflating: data/59.jpg             \n",
            "  inflating: data/6.jpeg             \n",
            "  inflating: data/60.jpg             \n",
            "  inflating: data/61.jpg             \n",
            "  inflating: data/62.jpg             \n",
            "  inflating: data/63.jpg             \n",
            "  inflating: data/64.jpg             \n",
            "  inflating: data/65.jpg             \n",
            "  inflating: data/66.jpg             \n",
            "  inflating: data/67.jpg             \n",
            "  inflating: data/68.jpg             \n",
            "  inflating: data/69.jpg             \n",
            "  inflating: data/7.jpeg             \n",
            "  inflating: data/70.jpg             \n",
            "  inflating: data/71.jpg             \n",
            "  inflating: data/72.jpg             \n",
            "  inflating: data/73.jpg             \n",
            "  inflating: data/74.jpg             \n",
            "  inflating: data/75.jpg             \n",
            "  inflating: data/76.jpg             \n",
            "  inflating: data/77.jpg             \n",
            "  inflating: data/78.jpg             \n",
            "  inflating: data/79.jpg             \n",
            "  inflating: data/8.jpeg             \n",
            "  inflating: data/80.jpg             \n",
            "  inflating: data/81.jpg             \n",
            "  inflating: data/82.jpg             \n",
            "  inflating: data/83.jpg             \n",
            "  inflating: data/84.jpg             \n",
            "  inflating: data/85.jpg             \n",
            "  inflating: data/86.jpg             \n",
            "  inflating: data/87.jpg             \n",
            "  inflating: data/88.jpg             \n",
            "  inflating: data/89.jpg             \n",
            "  inflating: data/9.jpeg             \n",
            "  inflating: data/90.jpg             \n",
            "  inflating: data/91.jpg             \n",
            "  inflating: data/92.jpg             \n",
            "  inflating: data/93.jpg             \n",
            "  inflating: data/94.jpg             \n",
            "  inflating: data/95.jpg             \n",
            "  inflating: data/96.jpg             \n",
            "  inflating: data/97.jpg             \n",
            "  inflating: data/98.jpg             \n",
            "  inflating: data/99.jpg             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "R5_b4817yl_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import h5py\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from random import seed, choice, sample\n",
        "from scipy.misc import imread, imresize\n",
        "import torch\n",
        "import torch.optim\n",
        "import torchvision\n",
        "import torch.nn as nn \n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "metadata": {
        "id": "lXVy9bu8yl0X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define parameters"
      ],
      "metadata": {
        "id": "7QBtHvLb8DvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data parameters\n",
        "data_folder = '/content/data_processed'  # folder with data files saved by create_input_files.py\n",
        "data_name = 'custom_1_cap_per_img_1_min_word_freq'  # base name shared by data files"
      ],
      "metadata": {
        "id": "qsGdUfZm8Jk1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "emb_dim = 64  # dimension of word embeddings\n",
        "attention_dim = 64  # dimension of attention linear layers\n",
        "decoder_dim = 64  # dimension of decoder RNN\n",
        "dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "SknHT-kc8KqO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "start_epoch = 0\n",
        "epochs = 3  # number of epochs to train for (if early stopping is not triggered)\n",
        "epochs_since_improvement = 0  # keeps track of number of epochs since there's been an improvement in validation BLEU\n",
        "batch_size = 16\n",
        "workers = 1  # for data-loading; right now, only 1 works with h5py\n",
        "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
        "decoder_lr = 4e-4  # learning rate for decoder\n",
        "grad_clip = 5.  # clip gradients at an absolute value of\n",
        "alpha_c = 1.  # regularization parameter for 'doubly stochastic attention', as in the paper\n",
        "best_bleu4 = 0.  # BLEU-4 score right now\n",
        "print_freq = 5  # print training/validation stats every __ batches\n",
        "fine_tune_encoder = False\n",
        "checkpoint = None"
      ],
      "metadata": {
        "id": "34LOMhIC8GLB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "Pk3U8kFO4beO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess dataset"
      ],
      "metadata": {
        "id": "5eaigFGY5Rbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_input_files(dataset, karpathy_json_path, image_folder, captions_per_image, min_word_freq, output_folder, max_len=100):\n",
        "    assert dataset in {'coco', 'flickr8k', 'flickr30k','custom'}\n",
        "    # Read Karpathy JSON\n",
        "    with open(karpathy_json_path, 'r') as j:\n",
        "        data = json.load(j)\n",
        "    # Read image paths and captions for each image\n",
        "    train_image_paths = []\n",
        "    train_image_captions = []\n",
        "    val_image_paths = []\n",
        "    val_image_captions = []\n",
        "    test_image_paths = []\n",
        "    test_image_captions = []\n",
        "    word_freq = Counter()\n",
        "    for img in data['images']:\n",
        "        captions = []\n",
        "        for c in img['sentences']:\n",
        "            # Update word frequency\n",
        "            word_freq.update(c['tokens'])\n",
        "            if len(c['tokens']) <= max_len:\n",
        "                captions.append(c['tokens'])\n",
        "        if len(captions) == 0:\n",
        "            continue\n",
        "        path = os.path.join(image_folder, img['filepath'], img['filename']) if dataset == 'coco' else os.path.join(\n",
        "            image_folder, img['filename'])\n",
        "        if img['split'] in {'train', 'restval'}:\n",
        "            train_image_paths.append(path)\n",
        "            train_image_captions.append(captions)\n",
        "        elif img['split'] in {'val'}:\n",
        "            val_image_paths.append(path)\n",
        "            val_image_captions.append(captions)\n",
        "        elif img['split'] in {'test'}:\n",
        "            test_image_paths.append(path)\n",
        "            test_image_captions.append(captions)\n",
        "    # Sanity check\n",
        "    assert len(train_image_paths) == len(train_image_captions)\n",
        "    assert len(val_image_paths) == len(val_image_captions)\n",
        "    assert len(test_image_paths) == len(test_image_captions)\n",
        "    # Create word map\n",
        "    words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
        "    word_map = {k: v + 1 for v, k in enumerate(words)}\n",
        "    word_map['<unk>'] = len(word_map) + 1\n",
        "    word_map['<start>'] = len(word_map) + 1\n",
        "    word_map['<end>'] = len(word_map) + 1\n",
        "    word_map['<pad>'] = 0\n",
        "    # Create a base/root name for all output files\n",
        "    base_filename = dataset + '_' + str(captions_per_image) + '_cap_per_img_' + str(min_word_freq) + '_min_word_freq'\n",
        "    # Save word map to a JSON\n",
        "    with open(os.path.join(output_folder, 'WORDMAP_' + base_filename + '.json'), 'w') as j:\n",
        "        json.dump(word_map, j)\n",
        "    # Sample captions for each image, save images to HDF5 file, and captions and their lengths to JSON files\n",
        "    seed(123)\n",
        "    for impaths, imcaps, split in [(train_image_paths, train_image_captions, 'TRAIN'),\n",
        "                                   (val_image_paths, val_image_captions, 'VAL'),\n",
        "                                   (test_image_paths, test_image_captions, 'TEST')]:\n",
        "        with h5py.File(os.path.join(output_folder, split + '_IMAGES_' + base_filename + '.hdf5'), 'a') as h:\n",
        "            # Make a note of the number of captions we are sampling per image\n",
        "            h.attrs['captions_per_image'] = captions_per_image\n",
        "            # Create dataset inside HDF5 file to store images\n",
        "            images = h.create_dataset('images', (len(impaths), 3, 256, 256), dtype='uint8')\n",
        "            print(\"\\nReading %s images and captions, storing to file...\\n\" % split)\n",
        "            enc_captions = []\n",
        "            caplens = []\n",
        "            for i, path in enumerate(tqdm(impaths)):\n",
        "                # Sample captions\n",
        "                if len(imcaps[i]) < captions_per_image:\n",
        "                    captions = imcaps[i] + [choice(imcaps[i]) for _ in range(captions_per_image - len(imcaps[i]))]\n",
        "                else:\n",
        "                    captions = sample(imcaps[i], k=captions_per_image)\n",
        "                # Sanity check\n",
        "                assert len(captions) == captions_per_image\n",
        "                # Read images\n",
        "                img = imread(impaths[i])\n",
        "                if len(img.shape) == 2:\n",
        "                    img = img[:, :, np.newaxis]\n",
        "                    img = np.concatenate([img, img, img], axis=2)\n",
        "                img = imresize(img, (256, 256))\n",
        "                img = img.transpose(2, 0, 1)\n",
        "                assert img.shape == (3, 256, 256)\n",
        "                assert np.max(img) <= 255\n",
        "                # Save image to HDF5 file\n",
        "                images[i] = img\n",
        "                for j, c in enumerate(captions):\n",
        "                    # Encode captions\n",
        "                    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in c] + [\n",
        "                        word_map['<end>']] + [word_map['<pad>']] * (max_len - len(c))\n",
        "                    # Find caption lengths\n",
        "                    c_len = len(c) + 2\n",
        "                    enc_captions.append(enc_c)\n",
        "                    caplens.append(c_len)\n",
        "            # Sanity check\n",
        "            assert images.shape[0] * captions_per_image == len(enc_captions) == len(caplens)\n",
        "            # Save encoded captions and their lengths to JSON files\n",
        "            with open(os.path.join(output_folder, split + '_CAPTIONS_' + base_filename + '.json'), 'w') as j:\n",
        "                json.dump(enc_captions, j)\n",
        "            with open(os.path.join(output_folder, split + '_CAPLENS_' + base_filename + '.json'), 'w') as j:\n",
        "                json.dump(caplens, j)"
      ],
      "metadata": {
        "id": "NDJX7aJ45PqJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data_processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXZXI0wyE5f-",
        "outputId": "29d6a11a-7cd7-4494-c553-cf80efda0f45"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'data_processed': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/data_processed', exist_ok=True)"
      ],
      "metadata": {
        "id": "1T7plUr7_740"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_input_files(dataset='custom', karpathy_json_path='/content/data.json', image_folder='/content/data/', captions_per_image=1, min_word_freq=1, output_folder='/content/data_processed', max_len=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e284fd8f92af46a58ae8236b2adbd69c",
            "6af4d119a92e49c08e06ef73e011166d",
            "1f8e4998eb8d43bab378afb9e60a11c1",
            "2aab8bec1dff48eb9dd1e0d8039664bc",
            "c376b766a39f4c0c8bb4cf1e6bb82ec0",
            "2638d11a7dcd4626afaf81ee7d93b312",
            "d3c8b46fbb42417d9fc808aaa58515ac",
            "adb071d093f94c2fa42a1619d16f37e7",
            "524a40c1f4134ea8b27352a88c4e706f",
            "f499e997eab94603bc85e233c3b9d326",
            "d169a0270e1343e1821f4b93e961100f",
            "cc38737926da414e8499272bec72ec89",
            "73fcc29969874f27bfe116f335326dd9",
            "365bdc1cfdfd4c94b6aaea0be1abc528",
            "b00379fd307b4c959200bcad16679d33",
            "5699694818254d199f9c4cc5dd938883",
            "f0a86f90ceec4e72a4ee4e413705f93d",
            "fce30c68b50c451db8b1534692ed4225",
            "2164ad6388194dc68c1fc8a98ea53ebb",
            "43ec48e4a2504abbb56b0b2e18b780b0",
            "17cb051dafef476f9a400e31da31d8d6",
            "45b6dd57a2194b3bb7bac23bb889069c",
            "cd82d041a1314655a29509b0fe35ee73",
            "88eedcc1db5440848fbbfe7eaf7fb32c",
            "f214fb40840d4e4197da005e58c8cf35",
            "fc11f0671beb4bc0b8ddcf4f3c3eb3d0",
            "5c217c78db6b4d998bdc5d1bbf4b6d38",
            "9d53703d84da49d98551241451fe344d",
            "99e046e350cb487ca33577b21e1bcb26",
            "6494f54475cd40a0bb857e58e8c810fb",
            "46f997effcfc47c7bcdacbb2eb6a20bb",
            "de1b31bfcacb40a7baecb2120358463d",
            "89b8fc79b6054408809a9241cfe60276"
          ],
          "height": 408
        },
        "id": "KbOS6nx65t9O",
        "outputId": "29686cb0-3fd1-4db1-e19c-49ba17db96ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading TRAIN images and captions, storing to file...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/76 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e284fd8f92af46a58ae8236b2adbd69c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-8c7a00434ac7>:72: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "  img = imread(impaths[i])\n",
            "<ipython-input-8-8c7a00434ac7>:76: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``skimage.transform.resize`` instead.\n",
            "  img = imresize(img, (256, 256))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading VAL images and captions, storing to file...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc38737926da414e8499272bec72ec89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading TEST images and captions, storing to file...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd82d041a1314655a29509b0fe35ee73"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define dataset class "
      ],
      "metadata": {
        "id": "tsWtOHbJ7U-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CaptionDataset(Dataset):\n",
        "    def __init__(self, data_folder, data_name, split, transform=None):\n",
        "        self.split = split\n",
        "        assert self.split in {'TRAIN', 'VAL', 'TEST'}\n",
        "        # Open hdf5 file where images are stored\n",
        "        self.h = h5py.File(os.path.join(data_folder, self.split + '_IMAGES_' + data_name + '.hdf5'), 'r')\n",
        "        self.imgs = self.h['images']\n",
        "        # Captions per image\n",
        "        self.cpi = self.h.attrs['captions_per_image']\n",
        "        # Load encoded captions (completely into memory)\n",
        "        with open(os.path.join(data_folder, self.split + '_CAPTIONS_' + data_name + '.json'), 'r') as j:\n",
        "            self.captions = json.load(j)\n",
        "        # Load caption lengths (completely into memory)\n",
        "        with open(os.path.join(data_folder, self.split + '_CAPLENS_' + data_name + '.json'), 'r') as j:\n",
        "            self.caplens = json.load(j)\n",
        "        # PyTorch transformation pipeline for the image (normalizing, etc.)\n",
        "        self.transform = transform\n",
        "        # Total number of datapoints\n",
        "        self.dataset_size = len(self.captions)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # Remember, the Nth caption corresponds to the (N // captions_per_image)th image\n",
        "        img = torch.FloatTensor(self.imgs[i // self.cpi] / 255.)\n",
        "        if self.transform != None:\n",
        "            img = self.transform(img)\n",
        "        caption = torch.LongTensor(self.captions[i])\n",
        "        caplen = torch.LongTensor([self.caplens[i]])\n",
        "        if (self.split == 'TRAIN'):\n",
        "            return img, caption, caplen\n",
        "        else:\n",
        "            # For validation of testing, also return all 'captions_per_image' captions to find BLEU-4 score\n",
        "            all_captions = torch.LongTensor(\n",
        "                self.captions[((i // self.cpi) * self.cpi):(((i // self.cpi) * self.cpi) + self.cpi)])\n",
        "            return img, caption, caplen, all_captions\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size"
      ],
      "metadata": {
        "id": "wdfihjvc5t7E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read word map\n",
        "word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n",
        "with open(word_map_file, 'r') as j:\n",
        "    word_map = json.load(j)"
      ],
      "metadata": {
        "id": "kpNNvjGzDXiJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataloaders\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "train_loader = torch.utils.data.DataLoader(CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])), batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(CaptionDataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])), batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)"
      ],
      "metadata": {
        "id": "wiGoXzPU83FC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model"
      ],
      "metadata": {
        "id": "6ubSsz0U8nLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define encoder model"
      ],
      "metadata": {
        "id": "mNjElQ2UEiJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoded_image_size=14):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_image_size = encoded_image_size\n",
        "        resnet = torchvision.models.resnet101(pretrained=True)  # pretrained ImageNet ResNet-101\n",
        "        # Remove linear and pool layers (since we're not doing classification)\n",
        "        modules = list(resnet.children())[:-2]\n",
        "        self.resnet = nn.Sequential(*modules)\n",
        "        # Resize image to fixed size to allow input images of variable size\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))\n",
        "        self.fine_tune()\n",
        "\n",
        "    def forward(self, images):\n",
        "        out = self.resnet(images)  # (batch_size, 2048, image_size/32, image_size/32)\n",
        "        out = self.adaptive_pool(out)  # (batch_size, 2048, encoded_image_size, encoded_image_size)\n",
        "        out = out.permute(0, 2, 3, 1)  # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
        "        return out\n",
        "\n",
        "    def fine_tune(self, fine_tune=True):\n",
        "        for p in self.resnet.parameters():\n",
        "            p.requires_grad = False\n",
        "        # If fine-tuning, only fine-tune convolutional blocks 2 through 4\n",
        "        for c in list(self.resnet.children())[5:]:\n",
        "            for p in c.parameters():\n",
        "                p.requires_grad = fine_tune"
      ],
      "metadata": {
        "id": "jyf5UQ89EiJq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define decoder model"
      ],
      "metadata": {
        "id": "3vd2XCo7EiJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)  # linear layer to transform encoded image\n",
        "        self.decoder_att = nn.Linear(decoder_dim, attention_dim)  # linear layer to transform decoder's output\n",
        "        self.full_att = nn.Linear(attention_dim, 1)  # linear layer to calculate values to be softmax-ed\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)  # softmax layer to calculate weights\n",
        "\n",
        "    def forward(self, encoder_out, decoder_hidden):\n",
        "        att1 = self.encoder_att(encoder_out)  # (batch_size, num_pixels, attention_dim)\n",
        "        att2 = self.decoder_att(decoder_hidden)  # (batch_size, attention_dim)\n",
        "        att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2)  # (batch_size, num_pixels)\n",
        "        alpha = self.softmax(att)  # (batch_size, num_pixels)\n",
        "        attention_weighted_encoding = (encoder_out * alpha.unsqueeze(2)).sum(dim=1)  # (batch_size, encoder_dim)\n",
        "        return attention_weighted_encoding, alpha\n",
        "\n",
        "\n",
        "class DecoderWithAttention(nn.Module):\n",
        "    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, encoder_dim=2048, dropout=0.5):\n",
        "        super(DecoderWithAttention, self).__init__()\n",
        "        self.encoder_dim = encoder_dim\n",
        "        self.attention_dim = attention_dim\n",
        "        self.embed_dim = embed_dim\n",
        "        self.decoder_dim = decoder_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.dropout = dropout\n",
        "        self.attention = Attention(encoder_dim, decoder_dim, attention_dim)  # attention network\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)  # embedding layer\n",
        "        self.dropout = nn.Dropout(p=self.dropout)\n",
        "        self.decode_step = nn.LSTMCell(embed_dim + encoder_dim, decoder_dim, bias=True)  # decoding LSTMCell\n",
        "        self.init_h = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial hidden state of LSTMCell\n",
        "        self.init_c = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial cell state of LSTMCell\n",
        "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)  # linear layer to create a sigmoid-activated gate\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc = nn.Linear(decoder_dim, vocab_size)  # linear layer to find scores over vocabulary\n",
        "        self.init_weights()  # initialize some layers with the uniform distribution\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "        self.fc.bias.data.fill_(0)\n",
        "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "    def load_pretrained_embeddings(self, embeddings):\n",
        "        self.embedding.weight = nn.Parameter(embeddings)\n",
        "\n",
        "    def fine_tune_embeddings(self, fine_tune=True):\n",
        "        for p in self.embedding.parameters():\n",
        "            p.requires_grad = fine_tune\n",
        "\n",
        "    def init_hidden_state(self, encoder_out):\n",
        "        mean_encoder_out = encoder_out.mean(dim=1)\n",
        "        h = self.init_h(mean_encoder_out)  # (batch_size, decoder_dim)\n",
        "        c = self.init_c(mean_encoder_out)\n",
        "        return h, c\n",
        "\n",
        "    def forward(self, encoder_out, encoded_captions, caption_lengths):\n",
        "        batch_size = encoder_out.size(0)\n",
        "        encoder_dim = encoder_out.size(-1)\n",
        "        vocab_size = self.vocab_size\n",
        "\n",
        "        # Flatten image\n",
        "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
        "        num_pixels = encoder_out.size(1)\n",
        "\n",
        "        # Sort input data by decreasing lengths; why? apparent below\n",
        "        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim=0, descending=True)\n",
        "        encoder_out = encoder_out[sort_ind]\n",
        "        encoded_captions = encoded_captions[sort_ind]\n",
        "\n",
        "        # Embedding\n",
        "        embeddings = self.embedding(encoded_captions)  # (batch_size, max_caption_length, embed_dim)\n",
        "\n",
        "        # Initialize LSTM state\n",
        "        h, c = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
        "\n",
        "        # We won't decode at the <end> position, since we've finished generating as soon as we generate <end>\n",
        "        # So, decoding lengths are actual lengths - 1\n",
        "        decode_lengths = (caption_lengths - 1).tolist()\n",
        "\n",
        "        # Create tensors to hold word predicion scores and alphas\n",
        "        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(device)\n",
        "        alphas = torch.zeros(batch_size, max(decode_lengths), num_pixels).to(device)\n",
        "\n",
        "        # At each time-step, decode by\n",
        "        # attention-weighing the encoder's output based on the decoder's previous hidden state output\n",
        "        # then generate a new word in the decoder with the previous word and the attention weighted encoding\n",
        "        for t in range(max(decode_lengths)):\n",
        "            batch_size_t = sum([l > t for l in decode_lengths])\n",
        "            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],\n",
        "                                                                h[:batch_size_t])\n",
        "            gate = self.sigmoid(self.f_beta(h[:batch_size_t]))  # gating scalar, (batch_size_t, encoder_dim)\n",
        "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
        "            h, c = self.decode_step(\n",
        "                torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1),\n",
        "                (h[:batch_size_t], c[:batch_size_t]))  # (batch_size_t, decoder_dim)\n",
        "            preds = self.fc(self.dropout(h))  # (batch_size_t, vocab_size)\n",
        "            predictions[:batch_size_t, t, :] = preds\n",
        "            alphas[:batch_size_t, t, :] = alpha\n",
        "\n",
        "        return predictions, encoded_captions, decode_lengths, alphas, sort_ind"
      ],
      "metadata": {
        "id": "wNrGU-VIEiJq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load checkpoint (if any)"
      ],
      "metadata": {
        "id": "5faCEXlq8rJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize / load checkpoint\n",
        "if checkpoint is None:\n",
        "    decoder = DecoderWithAttention(attention_dim=attention_dim, embed_dim=emb_dim, decoder_dim=decoder_dim, vocab_size=len(word_map), dropout=dropout)\n",
        "    decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()), lr=decoder_lr)\n",
        "    encoder = Encoder()\n",
        "    encoder.fine_tune(fine_tune_encoder)\n",
        "    encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
        "                                            lr=encoder_lr) if fine_tune_encoder else None\n",
        "\n",
        "else:\n",
        "    checkpoint = torch.load(checkpoint)\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
        "    best_bleu4 = checkpoint['bleu-4']\n",
        "    decoder = checkpoint['decoder']\n",
        "    decoder_optimizer = checkpoint['decoder_optimizer']\n",
        "    encoder = checkpoint['encoder']\n",
        "    encoder_optimizer = checkpoint['encoder_optimizer']\n",
        "    if fine_tune_encoder is True and encoder_optimizer is None:\n",
        "        encoder.fine_tune(fine_tune_encoder)\n",
        "        encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
        "                                                lr=encoder_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "63463bfac7fd40ddbeaf06ad1e17ea72",
            "e05b78a4d3614be3bc9c77d90bea841d",
            "8da09e5096854ca08fcf081b386a363a",
            "280008a6ebc64b2fb3bba9229aad5c7d",
            "71b812a239c64793b049d80d7abd9ab8",
            "0f1d38d947e7417b9ecf3237800600c7",
            "97bd57b6166d4eaebe17e5ebc55f34fe",
            "f7b824012d2547fd84066fa2de962e6a",
            "908e4d82965c4b588bbc0cb75b735366",
            "6f52ef05259a4d658922776a239ab0bb",
            "a87744d0a4854cb3aa0b05257e5be59f"
          ],
          "height": 156
        },
        "id": "Xk52RYCI8nAj",
        "outputId": "731bd90a-b21e-4cf6-d935-a199ee0f01f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/171M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63463bfac7fd40ddbeaf06ad1e17ea72"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize model"
      ],
      "metadata": {
        "id": "qNq8ty7h8xuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to GPU, if available\n",
        "decoder = decoder.to(device)\n",
        "encoder = encoder.to(device)"
      ],
      "metadata": {
        "id": "zE17fb738v3E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "uCoISSpC80Ox"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "Cd5paV4n9SSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility functions for training"
      ],
      "metadata": {
        "id": "Ow1y_4aj-8rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer, decoder_optimizer, bleu4, is_best):\n",
        "    state = {'epoch': epoch, 'epochs_since_improvement': epochs_since_improvement, 'bleu-4': bleu4, 'encoder': encoder, 'decoder': decoder, 'encoder_optimizer': encoder_optimizer, 'decoder_optimizer': decoder_optimizer}\n",
        "    filename = 'checkpoint_' + data_name + '.pth.tar'\n",
        "    torch.save(state, filename)\n",
        "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
        "    if is_best:\n",
        "        torch.save(state, 'BEST_' + filename)"
      ],
      "metadata": {
        "id": "njfHI9NF9af5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)"
      ],
      "metadata": {
        "id": "t1J1E0e2-sZt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, shrink_factor):\n",
        "    print(\"\\nDECAYING learning rate.\")\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr'] * shrink_factor\n",
        "    print(\"The new learning rate is %f\\n\" % (optimizer.param_groups[0]['lr'],))"
      ],
      "metadata": {
        "id": "VNspRswP9dwC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "Om9QYo1_97YY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(scores, targets, k):\n",
        "    batch_size = targets.size(0)\n",
        "    _, ind = scores.topk(k, 1, True, True)\n",
        "    correct = ind.eq(targets.view(-1, 1).expand_as(ind))\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / batch_size)"
      ],
      "metadata": {
        "id": "IX04ZqWl-DiF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
        "    decoder.train()  # train mode (dropout and batchnorm is used)\n",
        "    encoder.train()\n",
        "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
        "    data_time = AverageMeter()  # data loading time\n",
        "    losses = AverageMeter()  # loss (per word decoded)\n",
        "    top5accs = AverageMeter()  # top5 accuracy\n",
        "    start = time.time()\n",
        "    # Batches\n",
        "    for i, (imgs, caps, caplens) in enumerate(train_loader):\n",
        "        data_time.update(time.time() - start)\n",
        "\n",
        "        # Move to GPU, if available\n",
        "        imgs = imgs.to(device)\n",
        "        caps = caps.to(device)\n",
        "        caplens = caplens.to(device)\n",
        "\n",
        "        # Forward prop.\n",
        "        imgs = encoder(imgs)\n",
        "        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
        "\n",
        "        # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
        "        targets = caps_sorted[:, 1:]\n",
        "\n",
        "        # Remove timesteps that we didn't decode at, or are pads\n",
        "        # pack_padded_sequence is an easy trick to do this\n",
        "        scores, *_ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
        "        targets, *_ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Add doubly stochastic attention regularization\n",
        "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
        "\n",
        "        # Back prop.\n",
        "        decoder_optimizer.zero_grad()\n",
        "        if encoder_optimizer is not None:\n",
        "            encoder_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        if grad_clip is not None:\n",
        "            clip_gradient(decoder_optimizer, grad_clip)\n",
        "            if encoder_optimizer is not None:\n",
        "                clip_gradient(encoder_optimizer, grad_clip)\n",
        "\n",
        "        # Update weights\n",
        "        decoder_optimizer.step()\n",
        "        if encoder_optimizer is not None:\n",
        "            encoder_optimizer.step()\n",
        "\n",
        "        # Keep track of metrics\n",
        "        top5 = accuracy(scores, targets, 5)\n",
        "        losses.update(loss.item(), sum(decode_lengths))\n",
        "        top5accs.update(top5, sum(decode_lengths))\n",
        "        batch_time.update(time.time() - start)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        # Print status\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
        "                                                                          batch_time=batch_time,\n",
        "                                                                          data_time=data_time, loss=losses,\n",
        "                                                                          top5=top5accs))"
      ],
      "metadata": {
        "id": "d0nVFFEc95CO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, encoder, decoder, criterion):\n",
        "    decoder.eval()  # eval mode (no dropout or batchnorm)\n",
        "    if encoder is not None:\n",
        "        encoder.eval()\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top5accs = AverageMeter()\n",
        "    start = time.time()\n",
        "    references = list()  # references (true captions) for calculating BLEU-4 score\n",
        "    hypotheses = list()  # hypotheses (predictions)\n",
        "\n",
        "    # explicitly disable gradient calculation to avoid CUDA memory error\n",
        "    # solves the issue #57\n",
        "    with torch.no_grad():\n",
        "        # Batches\n",
        "        for i, (imgs, caps, caplens, allcaps) in enumerate(val_loader):\n",
        "\n",
        "            # Move to device, if available\n",
        "            imgs = imgs.to(device)\n",
        "            caps = caps.to(device)\n",
        "            caplens = caplens.to(device)\n",
        "\n",
        "            # Forward prop.\n",
        "            if encoder is not None:\n",
        "                imgs = encoder(imgs)\n",
        "            scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
        "\n",
        "            # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
        "            targets = caps_sorted[:, 1:]\n",
        "\n",
        "            # Remove timesteps that we didn't decode at, or are pads\n",
        "            # pack_padded_sequence is an easy trick to do this\n",
        "            scores_copy = scores.clone()\n",
        "            scores, *_ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
        "            targets, *_ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            # Add doubly stochastic attention regularization\n",
        "            loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
        "\n",
        "            # Keep track of metrics\n",
        "            losses.update(loss.item(), sum(decode_lengths))\n",
        "            top5 = accuracy(scores, targets, 5)\n",
        "            #print(scores)\n",
        "            top5accs.update(top5, sum(decode_lengths))\n",
        "            batch_time.update(time.time() - start)\n",
        "\n",
        "            start = time.time()\n",
        "\n",
        "            if i % print_freq == 0:\n",
        "                print('Validation: [{0}/{1}]\\t'\n",
        "                      'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n",
        "                                                                                loss=losses, top5=top5accs))\n",
        "\n",
        "            # Store references (true captions), and hypothesis (prediction) for each image\n",
        "            # If for n images, we have n hypotheses, and references a, b, c... for each image, we need -\n",
        "            # references = [[ref1a, ref1b, ref1c], [ref2a, ref2b], ...], hypotheses = [hyp1, hyp2, ...]\n",
        "\n",
        "            # References\n",
        "            allcaps = allcaps[sort_ind]  # because images were sorted in the decoder\n",
        "            for j in range(allcaps.shape[0]):\n",
        "                img_caps = allcaps[j].tolist()\n",
        "                img_captions = list(\n",
        "                    map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<pad>']}],\n",
        "                        img_caps))  # remove <start> and pads\n",
        "                references.append(img_captions)\n",
        "\n",
        "            # Hypotheses\n",
        "            _, preds = torch.max(scores_copy, dim=2)\n",
        "            preds = preds.tolist()\n",
        "            temp_preds = list()\n",
        "            for j, p in enumerate(preds):\n",
        "                temp_preds.append(preds[j][:decode_lengths[j]])  # remove pads\n",
        "            preds = temp_preds\n",
        "            hypotheses.extend(preds)\n",
        "\n",
        "            assert len(references) == len(hypotheses)\n",
        "\n",
        "        # Calculate BLEU-4 scores\n",
        "        bleu4 = corpus_bleu(references, hypotheses)\n",
        "        print('\\n * LOSS - {loss.avg:.3f}, TOP-5 ACCURACY - {top5.avg:.3f}, BLEU-4 - {bleu}\\n'.format(loss=losses, top5=top5accs, bleu=bleu4))\n",
        "    return bleu4"
      ],
      "metadata": {
        "id": "ONvTzRHd9h-h"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "7XF45SEQFDYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Epochs\n",
        "for epoch in tqdm(range(start_epoch, epochs)):\n",
        "    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
        "    if epochs_since_improvement == 20:\n",
        "        break\n",
        "    if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
        "        adjust_learning_rate(decoder_optimizer, 0.8)\n",
        "        if fine_tune_encoder:\n",
        "            adjust_learning_rate(encoder_optimizer, 0.8)\n",
        "    # One epoch's training\n",
        "    train(train_loader=train_loader, encoder=encoder, decoder=decoder, criterion=criterion, encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer, epoch=epoch)\n",
        "\n",
        "    # One epoch's validation\n",
        "    recent_bleu4 = validate(val_loader=val_loader, encoder=encoder, decoder=decoder, criterion=criterion)\n",
        "\n",
        "    # Check if there was an improvement\n",
        "    is_best = recent_bleu4 > best_bleu4\n",
        "    best_bleu4 = max(recent_bleu4, best_bleu4)\n",
        "    if not is_best:\n",
        "        epochs_since_improvement += 1\n",
        "        print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
        "    else:\n",
        "        epochs_since_improvement = 0\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer, decoder_optimizer, recent_bleu4, is_best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "9cbb95d29ecd4a63b3d9735032a02c30",
            "5b45e965d69b47bb8bca9daefbe0cb7b",
            "d7f0c021923f42bc836fb8ed46bccc4a",
            "8df1b0e48dd94080964c1a3c071826f3",
            "c9c690a2212141469eaad0a41b7c3a69",
            "f4ded0612e7149c391af8442b3814a28",
            "a882b9c989cc4075b3b85f3dfd791b5d",
            "b2c8c26f9f094e5b910ddd28336afc98",
            "c2f39660aadc468abd5285e68e5b236e",
            "44dd53f5ac6f47f18e19c8e4ce6204f9",
            "e4a4e196afa0483fb9a0585b4fc7e3f3"
          ]
        },
        "id": "pVht37Q39RtN",
        "outputId": "fbe3c40a-cc55-4a25-9fbe-d1b8439e539a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cbb95d29ecd4a63b3d9735032a02c30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/5]\tBatch Time 9.521 (9.521)\tData Load Time 0.119 (0.119)\tLoss 3.5079 (3.5079)\tTop-5 Accuracy 71.910 (71.910)\n",
            "Validation: [0/1]\tBatch Time 5.354 (5.354)\tLoss 3.6119 (3.6119)\tTop-5 Accuracy 69.643 (69.643)\t\n",
            "\n",
            " * LOSS - 3.612, TOP-5 ACCURACY - 69.643, BLEU-4 - 1.4740564900137075e-231\n",
            "\n",
            "\n",
            "Epochs since last improvement: 2\n",
            "\n",
            "Epoch: [1][0/5]\tBatch Time 10.500 (10.500)\tData Load Time 0.149 (0.149)\tLoss 3.4994 (3.4994)\tTop-5 Accuracy 70.968 (70.968)\n",
            "Validation: [0/1]\tBatch Time 5.450 (5.450)\tLoss 3.5596 (3.5596)\tTop-5 Accuracy 67.857 (67.857)\t\n",
            "\n",
            " * LOSS - 3.560, TOP-5 ACCURACY - 67.857, BLEU-4 - 1.4740564900137075e-231\n",
            "\n",
            "\n",
            "Epochs since last improvement: 3\n",
            "\n",
            "Epoch: [2][0/5]\tBatch Time 9.524 (9.524)\tData Load Time 0.146 (0.146)\tLoss 3.3966 (3.3966)\tTop-5 Accuracy 77.011 (77.011)\n",
            "Validation: [0/1]\tBatch Time 5.234 (5.234)\tLoss 3.5146 (3.5146)\tTop-5 Accuracy 71.429 (71.429)\t\n",
            "\n",
            " * LOSS - 3.515, TOP-5 ACCURACY - 71.429, BLEU-4 - 1.4584558130772648e-231\n",
            "\n",
            "\n",
            "Epochs since last improvement: 4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "zqo3Bm0KGbYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_image_beam_search(encoder, decoder, image_path, word_map, beam_size=3):\n",
        "    k = beam_size\n",
        "    vocab_size = len(word_map)\n",
        "    # Read image and process\n",
        "    img = imread(image_path)\n",
        "    if len(img.shape) == 2:\n",
        "        img = img[:, :, np.newaxis]\n",
        "        img = np.concatenate([img, img, img], axis=2)\n",
        "    img = imresize(img, (256, 256))\n",
        "    img = img.transpose(2, 0, 1)\n",
        "    img = img / 255.\n",
        "    img = torch.FloatTensor(img).to(device)\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    transform = transforms.Compose([normalize])\n",
        "    image = transform(img)  # (3, 256, 256)\n",
        "    # Encode\n",
        "    image = image.unsqueeze(0)  # (1, 3, 256, 256)\n",
        "    encoder_out = encoder(image)  # (1, enc_image_size, enc_image_size, encoder_dim)\n",
        "    enc_image_size = encoder_out.size(1)\n",
        "    encoder_dim = encoder_out.size(3)\n",
        "\n",
        "    # Flatten encoding\n",
        "    encoder_out = encoder_out.view(1, -1, encoder_dim)  # (1, num_pixels, encoder_dim)\n",
        "    num_pixels = encoder_out.size(1)\n",
        "\n",
        "    # We'll treat the problem as having a batch size of k\n",
        "    encoder_out = encoder_out.expand(k, num_pixels, encoder_dim)  # (k, num_pixels, encoder_dim)\n",
        "\n",
        "    # Tensor to store top k previous words at each step; now they're just <start>\n",
        "    k_prev_words = torch.LongTensor([[word_map['<start>']]] * k).to(device)  # (k, 1)\n",
        "\n",
        "    # Tensor to store top k sequences; now they're just <start>\n",
        "    seqs = k_prev_words  # (k, 1)\n",
        "\n",
        "    # Tensor to store top k sequences' scores; now they're just 0\n",
        "    top_k_scores = torch.zeros(k, 1).to(device)  # (k, 1)\n",
        "\n",
        "    # Tensor to store top k sequences' alphas; now they're just 1s\n",
        "    seqs_alpha = torch.ones(k, 1, enc_image_size, enc_image_size).to(device)  # (k, 1, enc_image_size, enc_image_size)\n",
        "\n",
        "    # Lists to store completed sequences, their alphas and scores\n",
        "    complete_seqs = list()\n",
        "    complete_seqs_alpha = list()\n",
        "    complete_seqs_scores = list()\n",
        "\n",
        "    # Start decoding\n",
        "    step = 1\n",
        "    h, c = decoder.init_hidden_state(encoder_out)\n",
        "\n",
        "    # s is a number less than or equal to k, because sequences are removed from this process once they hit <end>\n",
        "    while True:\n",
        "        embeddings = decoder.embedding(k_prev_words).squeeze(1)  # (s, embed_dim)\n",
        "        awe, alpha = decoder.attention(encoder_out, h)  # (s, encoder_dim), (s, num_pixels)\n",
        "        alpha = alpha.view(-1, enc_image_size, enc_image_size)  # (s, enc_image_size, enc_image_size)\n",
        "        gate = decoder.sigmoid(decoder.f_beta(h))  # gating scalar, (s, encoder_dim)\n",
        "        awe = gate * awe\n",
        "        h, c = decoder.decode_step(torch.cat([embeddings, awe], dim=1), (h, c))  # (s, decoder_dim)\n",
        "        scores = decoder.fc(h)  # (s, vocab_size)\n",
        "        scores = F.log_softmax(scores, dim=1)\n",
        "\n",
        "        # Add\n",
        "        scores = top_k_scores.expand_as(scores) + scores  # (s, vocab_size)\n",
        "\n",
        "        # For the first step, all k points will have the same scores (since same k previous words, h, c)\n",
        "        if step == 1:\n",
        "            top_k_scores, top_k_words = scores[0].topk(k, 0, True, True)  # (s)\n",
        "        else:\n",
        "            # Unroll and find top scores, and their unrolled indices\n",
        "            top_k_scores, top_k_words = scores.view(-1).topk(k, 0, True, True)  # (s)\n",
        "\n",
        "        # Convert unrolled indices to actual indices of scores\n",
        "        prev_word_inds = top_k_words / vocab_size  # (s)\n",
        "        next_word_inds = top_k_words % vocab_size  # (s)\n",
        "\n",
        "        # Add new words to sequences, alphas\n",
        "        seqs = torch.cat([seqs[prev_word_inds], next_word_inds.unsqueeze(1)], dim=1)  # (s, step+1)\n",
        "        seqs_alpha = torch.cat([seqs_alpha[prev_word_inds], alpha[prev_word_inds].unsqueeze(1)], dim=1)  # (s, step+1, enc_image_size, enc_image_size)\n",
        "\n",
        "        # Which sequences are incomplete (didn't reach <end>)?\n",
        "        incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n",
        "                           next_word != word_map['<end>']]\n",
        "        complete_inds = list(set(range(len(next_word_inds))) - set(incomplete_inds))\n",
        "\n",
        "        # Set aside complete sequences\n",
        "        if len(complete_inds) > 0:\n",
        "            complete_seqs.extend(seqs[complete_inds].tolist())\n",
        "            complete_seqs_alpha.extend(seqs_alpha[complete_inds].tolist())\n",
        "            complete_seqs_scores.extend(top_k_scores[complete_inds])\n",
        "        k -= len(complete_inds)  # reduce beam length accordingly\n",
        "\n",
        "        # Proceed with incomplete sequences\n",
        "        if k == 0:\n",
        "            break\n",
        "        seqs = seqs[incomplete_inds]\n",
        "        seqs_alpha = seqs_alpha[incomplete_inds]\n",
        "        h = h[prev_word_inds[incomplete_inds]]\n",
        "        c = c[prev_word_inds[incomplete_inds]]\n",
        "        encoder_out = encoder_out[prev_word_inds[incomplete_inds]]\n",
        "        top_k_scores = top_k_scores[incomplete_inds].unsqueeze(1)\n",
        "        k_prev_words = next_word_inds[incomplete_inds].unsqueeze(1)\n",
        "\n",
        "        # Break if things have been going on too long\n",
        "        if step > 50:\n",
        "            break\n",
        "        step += 1\n",
        "    i = complete_seqs_scores.index(max(complete_seqs_scores))\n",
        "    seq = complete_seqs[i]\n",
        "    alphas = complete_seqs_alpha[i]\n",
        "    return seq, alphas"
      ],
      "metadata": {
        "id": "usvL5VX9tp12"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load word map (word2ix)\n",
        "word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n",
        "with open(word_map_file, 'r') as j:\n",
        "    word_map = json.load(j)\n",
        "rev_word_map = {v: k for k, v in word_map.items()}  # ix2word"
      ],
      "metadata": {
        "id": "FLDqldhWJBsV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode, decode with attention and beam search\n",
        "seq, alphas = caption_image_beam_search(encoder, decoder, \"/content/data/12.jpeg\", word_map, 3)\n",
        "alphas = torch.FloatTensor(alphas)"
      ],
      "metadata": {
        "id": "ZYOLpeKKKC9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nEFE8d4Gdu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9RuJUWfGdsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}